{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huvimal/Nhapmonphantichdulieuhocsau/blob/master/LAB7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7AyPLJU0w9g4"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "#nltk.download_shell()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6uV89w8w9g5",
        "outputId": "f558fbb1-24ad-4e28-d40c-a70d091007e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "nltk.download('gutenberg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVYEOxxDw9g5",
        "outputId": "8f7071de-9544-42ff-d8b8-00c38166c036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gutenberg files :  ['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
          ]
        }
      ],
      "source": [
        "gb = nltk.corpus.gutenberg\n",
        "print(\"Gutenberg files : \", gb.fileids())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "m7VTJ_xcw9g6"
      },
      "outputs": [],
      "source": [
        "macbeth = nltk.corpus.gutenberg.words('shakespeare-macbeth.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVOQqxPhw9g6",
        "outputId": "c9523071-5738-4c42-ebc8-69e2ec386ab1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23140"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(macbeth)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KGU2Ni8w9g6",
        "outputId": "80754b64-63b6-426e-f96c-200fed45f7c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[',\n",
              " 'The',\n",
              " 'Tragedie',\n",
              " 'of',\n",
              " 'Macbeth',\n",
              " 'by',\n",
              " 'William',\n",
              " 'Shakespeare',\n",
              " '1603',\n",
              " ']']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "macbeth [:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2lKnI9Lw9g7",
        "outputId": "6c9da88f-5b80-42d3-90c6-32e54686b9b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['[',\n",
              "  'The',\n",
              "  'Tragedie',\n",
              "  'of',\n",
              "  'Macbeth',\n",
              "  'by',\n",
              "  'William',\n",
              "  'Shakespeare',\n",
              "  '1603',\n",
              "  ']'],\n",
              " ['Actus', 'Primus', '.'],\n",
              " ['Scoena', 'Prima', '.'],\n",
              " ['Thunder', 'and', 'Lightning', '.'],\n",
              " ['Enter', 'three', 'Witches', '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "nltk.download('punkt_tab')\n",
        "macbeth_sents = nltk.corpus.gutenberg.sents('shakespeare-macbeth.txt')\n",
        "macbeth_sents[:5]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvFmybE5w9g7",
        "outputId": "76a47220-4ecf-40a1-faf3-3ee1038a00c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 3 of 3 matches:\n",
            "nts with Dishes and Seruice ouer the Stage . Then enter Macbeth Macb . If it we\n",
            "with mans Act , Threatens his bloody Stage : byth ' Clock ' tis Day , And yet d\n",
            " struts and frets his houre vpon the Stage , And then is heard no more . It is \n"
          ]
        }
      ],
      "source": [
        "text = nltk.Text(macbeth)\n",
        "text.concordance('Stage')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvWd-2okw9g7",
        "outputId": "4442a7de-a962-4e13-bdf0-928f722fc243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the_. bloody_: the_,\n"
          ]
        }
      ],
      "source": [
        "text.common_contexts(['Stage'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl_Nqx6kw9g8",
        "outputId": "7d16c12d-2a2e-46e5-a27e-60751235fe4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day time face warre ayre king bleeding man reuolt serieant like\n",
            "knowledge broyle shew head spring heeles hare thane skie\n"
          ]
        }
      ],
      "source": [
        "text.similar('Stage')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LimtHbdgw9g8",
        "outputId": "113caa8e-8f04-43bb-f11b-05165c667194"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 1962),\n",
              " ('.', 1235),\n",
              " (\"'\", 637),\n",
              " ('the', 531),\n",
              " (':', 477),\n",
              " ('and', 376),\n",
              " ('I', 333),\n",
              " ('of', 315),\n",
              " ('to', 311),\n",
              " ('?', 241)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "fd = nltk.FreqDist(macbeth)\n",
        "fd.most_common(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb8rAY1dw9g8",
        "outputId": "6d3872db-94a8-4440-9dbb-3051b76a3195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-Ly976Sw9g8",
        "outputId": "54f74206-2cec-4d33-bb78-82e7ff0449be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "198\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['no', 'about', 'hers', 'at', \"won't\", \"i'll\", 'by', 'had', 'own', 'too']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "sw = set(nltk.corpus.stopwords.words('english'))\n",
        "print(len(sw))\n",
        "list(sw)[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAybTgtiw9g9",
        "outputId": "33dac352-d25f-4a4b-dac5-51c7378a9536"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14946"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "macbeth_filtered = [w for w in macbeth if w.lower() not in sw]\n",
        "len(macbeth_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C5rEKQyw9g9",
        "outputId": "d1142edf-82d8-4c48-a614-2bc41ae182f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 1962),\n",
              " ('.', 1235),\n",
              " (\"'\", 637),\n",
              " (':', 477),\n",
              " ('?', 241),\n",
              " ('Macb', 137),\n",
              " ('haue', 117),\n",
              " ('-', 100),\n",
              " ('Enter', 80),\n",
              " ('thou', 63)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "fd = nltk.FreqDist(macbeth_filtered)\n",
        "fd.most_common(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX-M-0o_w9g9",
        "outputId": "14bb2678-f573-4b2b-d5ef-443984849a88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('macb', 137),\n",
              " ('haue', 122),\n",
              " ('thou', 90),\n",
              " ('enter', 81),\n",
              " ('shall', 68),\n",
              " ('macbeth', 62),\n",
              " ('vpon', 62),\n",
              " ('thee', 61),\n",
              " ('macd', 58),\n",
              " ('vs', 57)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import string\n",
        "punctuation = set(string.punctuation)\n",
        "macbeth_filtered2 = [w.lower() for w in macbeth if w.lower() not in sw and w.lower() not in punctuation]\n",
        "fd = nltk.FreqDist(macbeth_filtered2)\n",
        "fd.most_common(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bvixd6ASw9g9",
        "outputId": "a3edeec5-27b0-4484-a319-4d2e50244ac4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Assassination',\n",
              " 'Chamberlaines',\n",
              " 'Distinguishes',\n",
              " 'Gallowgrosses',\n",
              " 'Metaphysicall',\n",
              " 'Northumberland',\n",
              " 'Voluptuousnesse',\n",
              " 'commendations',\n",
              " 'multitudinous',\n",
              " 'supernaturall',\n",
              " 'vnaccompanied']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "long_words = [w for w in macbeth if len(w)> 12]\n",
        "sorted(long_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xQW19s9w9g9",
        "outputId": "73e2119f-4581-4f7a-f5aa-e20ffdb23025"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Auaricious',\n",
              " 'Gracious',\n",
              " 'Industrious',\n",
              " 'Iudicious',\n",
              " 'Luxurious',\n",
              " 'Malicious',\n",
              " 'Obliuious',\n",
              " 'Pious',\n",
              " 'Rebellious',\n",
              " 'compunctious',\n",
              " 'furious',\n",
              " 'gracious',\n",
              " 'pernicious',\n",
              " 'pernitious',\n",
              " 'pious',\n",
              " 'precious',\n",
              " 'rebellious',\n",
              " 'sacrilegious',\n",
              " 'serious',\n",
              " 'spacious',\n",
              " 'tedious']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "ious_words = [w for w in macbeth if 'ious' in w]\n",
        "ious_words = set(ious_words)\n",
        "sorted(ious_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THDqIrFFw9g-",
        "outputId": "1849ea23-cd35-4458-84a3-c238df8953a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('enter', 'macbeth'), 16),\n",
              " (('exeunt', 'scena'), 15),\n",
              " (('thane', 'cawdor'), 13),\n",
              " (('knock', 'knock'), 10),\n",
              " (('st', 'thou'), 9),\n",
              " (('thou', 'art'), 9),\n",
              " (('lord', 'macb'), 9),\n",
              " (('haue', 'done'), 8),\n",
              " (('macb', 'haue'), 8),\n",
              " (('good', 'lord'), 8),\n",
              " (('let', 'vs'), 7),\n",
              " (('enter', 'lady'), 7),\n",
              " (('wee', 'l'), 7),\n",
              " (('would', 'st'), 6),\n",
              " (('macbeth', 'macb'), 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "bgrms = nltk.FreqDist(nltk.bigrams(macbeth_filtered2))\n",
        "bgrms.most_common(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlqtyKaGw9g-",
        "outputId": "965603e2-f63f-4c91-ccea-00c87cdf00a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('knock', 'knock', 'knock'), 6),\n",
              " (('enter', 'macbeth', 'macb'), 5),\n",
              " (('enter', 'three', 'witches'), 4),\n",
              " (('exeunt', 'scena', 'secunda'), 4),\n",
              " (('good', 'lord', 'macb'), 4),\n",
              " (('three', 'witches', '1'), 3),\n",
              " (('exeunt', 'scena', 'tertia'), 3),\n",
              " (('thunder', 'enter', 'three'), 3),\n",
              " (('exeunt', 'scena', 'quarta'), 3),\n",
              " (('scena', 'prima', 'enter'), 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "tgrms = nltk.FreqDist(nltk.trigrams (macbeth_filtered2))\n",
        "tgrms.most_common(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RTpZcvHfw9g-",
        "outputId": "54cdda76-801a-4ea7-85f0-f60f87f06f13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'*** START OF THE PROJECT GUTENBERG EBOOK 2554 ***\\n\\n\\n\\n\\nCRIME AND PUNISHMENT\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "from urllib import request\n",
        "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
        "response = request.urlopen(url)\n",
        "raw = response.read().decode('utf8')\n",
        "raw[:75]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MRyCYpXVw9g-",
        "outputId": "78d1a286-454a-459e-c6b9-c22837ef0643"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'*** START OF THE PROJECT GUTENBERG EBOOK 2554 ***\\n\\n\\n\\n\\nCRIME AND PUNISHMENT\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "from urllib import request\n",
        "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
        "response = request.urlopen(url)\n",
        "raw = response.read().decode('utf-8-sig')\n",
        "raw[:75]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdwdTuOhw9g-",
        "outputId": "0d6d083a-b296-4efe-e885-6432ac76c2d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['*',\n",
              " '*',\n",
              " '*',\n",
              " 'START',\n",
              " 'OF',\n",
              " 'THE',\n",
              " 'PROJECT',\n",
              " 'GUTENBERG',\n",
              " 'EBOOK',\n",
              " '2554',\n",
              " '*',\n",
              " '*']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "tokens = nltk.word_tokenize (raw)\n",
        "webtext = nltk.Text (tokens)\n",
        "webtext[:12]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "H_bLNbYhw9g-",
        "outputId": "6543b834-9d8f-474d-a1ca-517998e67d11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/loose.dtd\">\\r\\n<html>\\r\\n<hea'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "url = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\"\n",
        "html = request.urlopen(url).read().decode('utf8')\n",
        "html[:120]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ZF65KV3Tw9g_"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "raw = BeautifulSoup(html, \"lxml\").get_text()\n",
        "tokens = nltk.word_tokenize(raw)\n",
        "text = nltk.Text(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('movie_reviews')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC8Fd_i10tCH",
        "outputId": "14fba9e2-32d5-492e-eb05-864f0b5a101b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "reviews = nltk.corpus.movie_reviews\n",
        "documents = [(list(reviews.words(fileid)), category)\n",
        "for category in reviews.categories()\n",
        "for fileid in reviews.fileids(category)]\n",
        "random.shuffle(documents)"
      ],
      "metadata": {
        "id": "akjAECh00x3b"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_review = ' '.join(documents[0][0])\n",
        "print(first_review)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmM6l6JF15Yf",
        "outputId": "ff264c69-0516-42d8-8788-d337400bdb7c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\" say , any of you know how to madison ? \" --- brad \" asshole \" majors ( barry bostwick ) shows just how unhip he is after watching the kooky transylvanians wrap up their ode to the time warp in the cult classic the rocky horror picture show . the story behind the rocky horror picture show is one of legend . in the early 70 ' s , stage actor turned first - time playwright richard o ' brien decided he wanted to make a musical homage to the crazy b - movies he had grown up with as a child , set to a bunch of catchy rock tunes of his own design . the result was the stage play the rocky horror show , which opened to fairly decent reviews in london in 1973 and was even hailed the best musical of 1973 by prominent drama critics in england . the play was so successful that the film rights were immediately snapped up and production on the film began a mere year later , in october of 1974 . the film version ( now titled the rocky horror picture show ) was released in 1975 . . . and immediately tanked at the box office . whether it was because fox wasn ' t quite sure how to market it to audiences or that audiences didn ' t quite know what to make of it themselves has never really been determined , but the one common bit of knowledge about the film was that it was a huge flop . it seemed that the infectious spirit brought about by the stage version had not been infused into the film version and fox quickly had it pulled from theaters . a year later , something entirely strange and magical happened . prints of the film started to be distributed to theaters in small amounts and were circulating at midnight shows across the country , and it was then that a whole new audience found the film . this new audience was prone to dressing up like the characters from the film , acting out segments in front of the screen as the movie played , yelling rude comments at the screen , and just generally having a good time . word quickly spread about this new phenomena of interactive film and the rocky horror picture show ' s life as the ultimate cult film was born . for the virgins out there who are unaware , the plot centers around a loving couple , brad majors ( barry bostwick ) and janet weiss ( susan sarandon ) , who come from a small town called denton . brad and janet have just attended the wedding of two of their friends and decide that they also want to be wed . they plan a trip to see the man who led to their meeting , dr . everett scott ( jonathan adams , who played the narrator in the original stage version ) , but their car gets a flat on the way to his home . remembering a castle they had seen back a few miles down the road , they decide to walk there and see if the residents have a phone they might be able to use to call for assistance . the castle is actually the home of a race of aliens from the planet transsexual ( in the galaxy of transylvania ) , who are lead by the eccentric fishnet - stocking wearing mad scientist dr . frank - n - furter ( tim curry ) . frank - n - furter has masterminded the secret to creating life and has done so in the form of rocky ( peter hinwood ) . as rocky becomes accustomed to his new environment , brad and janet find themselves at the mercy of frank - n - furter ' s mad schemes . little do any of them know that the doctor ' s handyman , riff - raff ( original author richard o ' brien ) , and domestic , magenta ( patricia quinn ) , are actually transsexual planetary protectors who have been sent to stop frank from spreading his alien evil all over the earth . going back and revisiting this film after ten years ( 1990 being the first time i had ever seen it ) , it is amazing to me that this film ever got made or has had the staying power that it has . if i had been a fox executive around the time of its release , i don ' t think i would have known what to make of it either . for all intents and purposes it is a bad movie ( though bad in a really good sort of way ) , but sumptuous production design and a great deal of incredibly catchy songs really help to increase the likability of the film . by the time the credits role , it is fairly easy to have gotten wrapped up in the film and its characters , and one really gets the feeling that richard o ' brien definitely was a fan of the old cheesy b - movies his film is based on . when i say that the wall - to - wall songs are catchy what i really mean to say is that , once you hear them , they will be ingrained in your head for all of eternity . it goes without saying that the \" time warp \" is the most popular song in the film . even people who have never seen the movie know of that particular song . what those who haven ' t seen the movie don ' t know though , is that there are even more songs in the film that are just as worthy of acknowledgment . my personal favorite is \" over at the frankenstein place \" , but \" dammit janet \" is also maddeningly catchy . tim curry ' s vocals on the rocking tune \" sweet transvestite \" need to be heard to be believed . the finale of the film , a big floor show staged by frank - n - furter and featuring most of the cast in garters and fishnets ( including barry bostwick . . . frightening ! ) , features no less than four songs ( \" rose tint my world \" , \" don ' t dream it \" , \" wild and untamed thing \" , and \" i ' m going home \" ) , all of which are immensely singable . the film ' s true popularity and longevity resides in its audience participation though . despite the catchiness of the songs , this movie would have been long forgotten about if it hadn ' t have been for the multitude of folks who dress up every friday or saturday night to rush out and be a part of their own little floor show . watching this film at home is nothing compared to actually experiencing this in a theater with hundreds of rabid fans ( unless you don ' t mind inviting friends over and letting them shoot water guns in your home or letting them throw rice and pieces of toast all over the place ) . note : director jim sharman brought back to the central characters of the film , in the form of a sequel , resulting in the very much forgotten film shock treatment , which picks up with brad and janet ( this time played by cliff de young and jessica harper ! ) as contestants on a game show in their home town of denton . the two are menaced by the evil tv station manager ( also played by de young ) , who wishes to claim janet as his own . o ' brien returned as a writer / performer on the project ( as did quinn , campbell , and gray in performance capacity only ) , but the film had nowhere near the spirit of the original . 25 years later , this film is still the pinnacle of cult filmdom and is continuously screened at midnight all over the world . as a lasting testament to the longevity of the film and its legion of fans , a brand new special edition 2 - disc dvd set has been released that is the most comprehensive compendium of rocky horror to date ( even out shining the laserdisc special edition that was released for its 20th anniversary ) . if you are one of those people who can ' t get enough of the film , this disc should be more than enough to satisfy your appetites . in an attempt to recreate the interactivity of the film , fox home entertainment has released this wonderful 2 - disc dvd set loaded with so many extras that it ' ll take a good eight hours just to take in the majority of it all . the film itself is located on the first disc and has been given a beautiful transfer that shows it in its original aspect ratio of 1 . 85 : 1 ( enhanced for 16x9 televisions ) . the film is presented in two different versions , the us theatrical version and the uk version which adds a musical number during the finale called \" superheroes \" . for ambitious viewers , the disc also includes a hidden version ( located on the main menu by clicking left from the scene selection menu choice and highlighting a pair of lips in the lower left corner ) which presents the film in the manner it was originally supposed to have been seen . originally , the film was to have been similar to the wizard of oz , with the first half of the it seen in black and white ( and not changing to color until the transylvanians are first revealed to brad and janet during the time warp musical number ) . most reports , including a documentary on the disc , say that the color was supposed to appear when frank - n - furter first shows up in the elevator , but it does seem to work better where it was placed on this version , depicting the vast difference between the world brad and janet were used to compared with the one to which they are introduced . the film contains a commentary track by show creator ( and faithful handyman ) richard o ' brien and co - star patricia quinn which is fairly enjoyable ( and quinn immediately starts off by refusing to speak about sarandon nearly contracting pneumonia while having to walk around wet and half - naked on freezing cold sets , which she apparently complained about the entire film and in future interviews ) . the two seem like old friends and have great stories to tell , but they also point out cast members that are sadly no longer with us anymore ( and there are quite a few ) . fox has also tried to recreate the feel of attending the film in a theater with several audience participation segments . the first feature ( and the most simple ) is a subtitle prompter which lets you know when to open up on people with your water guns or when the right time to throw your toast is . the second feature is an audience participation track , which lets you in on what you might hear on a good night out at the show . most of the comments are unintelligible because it is basically just a large group of people screaming their heads off , but every once and a while a comment can be heard that will invoke a bit of laughter . the final participation segment uses a technology very much like the technology used on the matrix dvd , where a pair of lips will appear on - screen during certain scenes of the film ( mostly during the musical numbers ) that can be selected by pressing enter on your remote . when selected , you will be taken out of the film and into a live participation version of the scene put on during one of the many screenings that occur all over the world . once the segment is over , you are deposited right back into the film where you left off . the first disc also contains a few dvd - rom goodies for those with that particular type of dvd player . there is a timeline of the evolution from the stage play version to worldwide cult sensation , a video jukebox , a you don ' t know jack - styled trivia game ( which is about as bare bones a you don ' t know jack parody as it can be ) , and a bizarre mad - libs styled word game known as riff - raff ' s story lab . links to the rocky horror websites are also available from the dvd - rom portion of the disc . the second disc features even more goodies for the person who loves extras . former lite - rock video channel turned music historians vh - 1 have allowed some of their outtake footage from the \" behind the music : rocky horror \" special that they ran earlier in the year to be shown here , as well as a pop - up video for the meat loaf - sung \" hot patootie \" . the \" behind the music \" segments are all very interesting , especially richard o ' brien ' s jaunt through the castle ( which is now a hotel ! ) where the film was originally shot . there are also extensions of the sarandon , bostwick , quinn , o ' brien , and meat loaf interviews . as far as extras for the film itself go , there are two deleted musical numbers that are also included here . one of which is just the \" superheroes \" number available in the uk version , but there is also another rare musical number presented here called \" once in a while \" . a series of alternate takes are also presented here , but none of them are really much of a revelation ( except for the undressing scene in which we see that patricia quinn is having a hard time unbuttoning barry bostwick ' s pants ) . for the completist who must have every little bit of rocky horror paraphernalia , a misprinted end sequence and alternate credit sequence are also presented here . rounding out the disc is a decent documentary called rocky horror double feature video show , two theatrical trailers ( proclaiming that the film is \" a different sort of jaws \" ) , a still gallery , and two sing - a - longs ( for \" toucha toucha touch me \" and \" sweet transvestite \" ) . fox ' s special edition is the dvd set that rocky horror fans have been waiting for all their lives ( \" you ' re lucky . . . i ' m lucky . . . he ' s lucky . . . we ' re all lucky ! \" ) . it ' s not just amazing enough that tons of classic italian films are finally getting their recognition in the u . s . , but even long standing traditions are finally receiving their due on the wonderful dvd format . as with their excellent dvds of the abyss , fight club , independence day , and the sound of music , fox shows that they have most certainly made the commitment to provide the things that dvd lovers want . i raise a toast to them ( cue the throwing of the bread ) as i cut out the lights , sit back , and watch those disembodied lips begin to sing about b - movie tradition . [ r ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bC7MC8no17g2",
        "outputId": "a7db0e64-6abe-42ca-fcee-1f85be625e54"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = nltk.FreqDist(w.lower() for w in reviews.words())\n",
        "word_features = list(all_words)"
      ],
      "metadata": {
        "id": "EezdDRa01-AG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def document_features(document, word_features):\n",
        " document_words = set(document)\n",
        " features = {}\n",
        " for word in word_features:\n",
        "  features['{}'.format(word)] = (word in document_words)\n",
        " return features"
      ],
      "metadata": {
        "id": "-Il2usZv1_s_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featuresets = [(document_features(d,word_features), c) for (d,c) in documents]\n",
        "len(featuresets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwrPd6Zf2ZfO",
        "outputId": "cfb03037-4b8a-4676-d5e4-b0d98671f183"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, test_set = featuresets[1500:], featuresets[:500]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n"
      ],
      "metadata": {
        "id": "NjagTRsr2kPr"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, est_set = featuresets[1500:], featuresets[:500]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDcdJRw724Ft",
        "outputId": "6f562762-e79f-456e-98bf-dc8488cb3f71"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.show_most_informative_features(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmiqERcu284n",
        "outputId": "47a0161b-0a25-4411-90a6-219d49bc63c4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "                  poorly = True              neg : pos    =     12.2 : 1.0\n",
            "             outstanding = True              pos : neg    =     11.8 : 1.0\n",
            "                   inept = True              neg : pos    =     10.8 : 1.0\n",
            "                 process = True              pos : neg    =     10.5 : 1.0\n",
            "                  golden = True              pos : neg    =      9.2 : 1.0\n",
            "                     joy = True              pos : neg    =      9.2 : 1.0\n",
            "             wonderfully = True              pos : neg    =      9.2 : 1.0\n",
            "                    bomb = True              neg : pos    =      8.7 : 1.0\n",
            "                  finest = True              pos : neg    =      8.6 : 1.0\n",
            "             magnificent = True              pos : neg    =      8.6 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Viết chương trình Python với thư viện NLTK để liệt kê các tên của copus.\n",
        "nltk.download('names')\n",
        "from nltk.corpus import names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPK3yTFfJyd3",
        "outputId": "1e9de823-0296-4297-98e2-fba88e7b178a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "male_names = names.words('male.txt')\n",
        "female_names = names.words('female.txt')\n",
        "\n",
        "print(\"10 tên nam đầu tiên:\", male_names[:10])\n",
        "print(\"10 tên nữ đầu tiên:\", female_names[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU1rpyLeKH8Y",
        "outputId": "40f467be-a8cc-4fd7-a221-bf7f1aa776e3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 tên nam đầu tiên: ['Aamir', 'Aaron', 'Abbey', 'Abbie', 'Abbot', 'Abbott', 'Abby', 'Abdel', 'Abdul', 'Abdulkarim']\n",
            "10 tên nữ đầu tiên: ['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi', 'Abbie', 'Abby', 'Abigael', 'Abigail', 'Abigale']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Viết chương trình Python với thư viện NLTK để liệt kê danh sách các stopword bằng các ngôn ngữ khác nhau.\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Liệt kê stopwords\n",
        "stopwords_english = stopwords.words('english')\n",
        "stopwords_french = stopwords.words('french')\n",
        "stopwords_spanish = stopwords.words('spanish')\n",
        "\n",
        "print(\"Stopwords tiếng Anh:\", stopwords_english[:10])  # In 10 từ đầu tiên\n",
        "print(\"Stopwords tiếng Pháp:\", stopwords_french[:10])\n",
        "print(\"Stopwords tiếng Tây Ban Nha:\", stopwords_spanish[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfLt97qFKelD",
        "outputId": "60d8683e-dfb4-44ed-dfa9-882f4e600a88"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopwords tiếng Anh: ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']\n",
            "Stopwords tiếng Pháp: ['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle']\n",
            "Stopwords tiếng Tây Ban Nha: ['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Viết chương trình Python với thư viện NLTK để kiểm tra danh sách các stopword bằng các ngôn ngữ khác nhau.\n",
        "# Kiểm tra stopword\n",
        "print(\"Có 'the' trong stopwords tiếng Anh?\", 'the' in stopwords_english)\n",
        "print(\"Có 'le' trong stopwords tiếng Pháp?\", 'le' in stopwords_french)\n",
        "print(\"Có 'el' trong stopwords tiếng Tây Ban Nha?\", 'el' in stopwords_spanish)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNoVN1oXKr8m",
        "outputId": "886eea93-0063-4e35-fcb1-d4c9bd8a5f78"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Có 'the' trong stopwords tiếng Anh? True\n",
            "Có 'le' trong stopwords tiếng Pháp? True\n",
            "Có 'el' trong stopwords tiếng Tây Ban Nha? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Viết chương trình Python với thư viện NLTK để loại bỏ các stopword từ một văn bản đã cho.\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"This is a sample text with some stop words.\"\n",
        "tokens = word_tokenize(text)\n",
        "filtered_words = [word for word in tokens if word.lower() not in stopwords_english]\n",
        "#5  Viết chương trình Python với thư viện NLTK bỏ qua các stopword từ danh sách các stopword.\n",
        "\n",
        "print(\"Văn bản sau khi loại bỏ stopwords:\", filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGtEq4_6K4RU",
        "outputId": "8f5d8eb1-750a-4fc5-e69a-e08079d5943e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Văn bản sau khi loại bỏ stopwords: ['sample', 'text', 'stop', 'words', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Viết một chương trình Python với thư viện NLTK để tìm định nghĩa và ví dụ của một từ đã cho bằng WordNet từ Wikipedia\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "nltk.download('wordnet')\n",
        "word = \"example\"\n",
        "synsets = wn.synsets(word)\n",
        "\n",
        "for syn in synsets:\n",
        "    print(f\"Định nghĩa: {syn.definition()}\")\n",
        "    print(f\"Ví dụ: {syn.examples()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHibsNGmLAHY",
        "outputId": "9062e567-8899-4d71-ba23-9cfe4c561058"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Định nghĩa: an item of information that is typical of a class or group\n",
            "Ví dụ: ['this patient provides a typical example of the syndrome', 'there is an example on page 10']\n",
            "Định nghĩa: a representative form or pattern\n",
            "Ví dụ: ['I profited from his example']\n",
            "Định nghĩa: something to be imitated\n",
            "Ví dụ: ['an exemplar of success', 'a model of clarity', 'he is the very model of a modern major general']\n",
            "Định nghĩa: punishment intended as a warning to others\n",
            "Ví dụ: ['they decided to make an example of him']\n",
            "Định nghĩa: an occurrence of something\n",
            "Ví dụ: ['it was a case of bad judgment', 'another instance occurred yesterday', 'but there is always the famous example of the Smiths']\n",
            "Định nghĩa: a task performed or problem solved in order to develop skill or understanding\n",
            "Ví dụ: ['you must work the examples at the end of each chapter in the textbook']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Viết chương trình Python với thư viện NLTK để tìm tập hợp các từ đồng nghĩa và trái nghĩa\n",
        "# Từ đồng nghĩa\n",
        "synonyms = []\n",
        "antonyms = []\n",
        "\n",
        "for syn in wn.synsets(\"good\"):\n",
        "    for lemma in syn.lemmas():\n",
        "        synonyms.append(lemma.name())  # Từ đồng nghĩa\n",
        "        if lemma.antonyms():\n",
        "            antonyms.append(lemma.antonyms()[0].name())  # Từ trái nghĩa\n",
        "\n",
        "print(\"Từ đồng nghĩa:\", set(synonyms))\n",
        "print(\"Từ trái nghĩa:\", set(antonyms))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdlAXM1uLkXk",
        "outputId": "972babab-affe-4bc8-b7cb-862ae96b582d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Từ đồng nghĩa: {'in_force', 'just', 'adept', 'serious', 'sound', 'thoroughly', 'effective', 'safe', 'soundly', 'trade_good', 'respectable', 'undecomposed', 'dear', 'dependable', 'ripe', 'skillful', 'commodity', 'good', 'secure', 'beneficial', 'full', 'skilful', 'well', 'expert', 'upright', 'goodness', 'proficient', 'near', 'in_effect', 'estimable', 'salutary', 'honorable', 'practiced', 'unspoilt', 'honest', 'unspoiled', 'right'}\n",
            "Từ trái nghĩa: {'bad', 'evil', 'ill', 'badness', 'evilness'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Viết chương trình Python với thư viện NLTK để có cái nhìn tổng quan về bộ tag, chi tiết của\n",
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download the 'averaged_perceptron_tagger' resource if not present\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "tokens = word_tokenize(sentence)\n",
        "\n",
        "print(\"Cái nhìn tổng quan về bộ tag:\", tokens)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTmVCpwZL4-3",
        "outputId": "ae812dd8-3c36-44e2-bcfe-10287eaee3df"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cái nhìn tổng quan về bộ tag: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#9. Viết chương trình Python với thư viện NLTK để so sánh sự giống nhau của hai danh từ đã cho.\n",
        "noun1 = wn.synset('car.n.01')\n",
        "noun2 = wn.synset('automobile.n.01')\n",
        "\n",
        "similarity = noun1.wup_similarity(noun2)\n",
        "print(\"Sự giống nhau giữa 'car' và 'automobile':\", similarity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpyvyK2DWUrY",
        "outputId": "2536c98e-0871-4e14-8688-731798b17d89"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sự giống nhau giữa 'car' và 'automobile': 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#10. Viết chương trình Python với thư viện NLTK để so sánh sự giống nhau của hai động từ đã cho.\n",
        "verb1 = wn.synset('run.v.01')\n",
        "verb2 = wn.synset('jog.v.01')\n",
        "\n",
        "similarity = verb1.wup_similarity(verb2)\n",
        "print(\"Sự giống nhau giữa 'run' và 'jog':\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl0Pr3bOWif1",
        "outputId": "4f2b60c8-4142-4fc2-9328-a1c884da315c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sự giống nhau giữa 'run' và 'jog': 0.18181818181818182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#11. Viết chương trình Python với thư viện NLTK để tìm số lượng tên nam và nữ trong các tên kho dữ liệu. In tên 10 nam và nữ đầu tiên.\n",
        "print(\"Số lượng tên nam:\", len(male_names))\n",
        "print(\"Số lượng tên nữ:\", len(female_names))\n",
        "\n",
        "print(\"10 tên nam đầu tiên:\", male_names[:10])\n",
        "print(\"10 tên nữ đầu tiên:\", female_names[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BtwO1jIWlsk",
        "outputId": "20239e53-6a78-4ec1-c812-d44d28059863"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số lượng tên nam: 2943\n",
            "Số lượng tên nữ: 5001\n",
            "10 tên nam đầu tiên: ['Aamir', 'Aaron', 'Abbey', 'Abbie', 'Abbot', 'Abbott', 'Abby', 'Abdel', 'Abdul', 'Abdulkarim']\n",
            "10 tên nữ đầu tiên: ['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi', 'Abbie', 'Abby', 'Abigael', 'Abigail', 'Abigale']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#12. Viết chương trình Python với thư viện NLTK để in 15 kết hợp ngẫu nhiên đầu tiên được gắn\n",
        "import random\n",
        "\n",
        "male_samples = random.sample(male_names, 15)\n",
        "female_samples = random.sample(female_names, 15)\n",
        "\n",
        "print(\"15 tên nam ngẫu nhiên:\", male_samples)\n",
        "print(\"15 tên nữ ngẫu nhiên:\", female_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsHIU2HEW2b8",
        "outputId": "75e9587d-b02a-49a7-c876-ae0c761ad496"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15 tên nam ngẫu nhiên: ['Bennet', 'Ronen', 'Mendel', 'Reinhold', 'Douglas', 'Adrick', 'Cooper', 'Georg', 'Andre', 'Griffith', 'Dugan', 'Emilio', 'Adair', 'Hazel', 'Jo']\n",
            "15 tên nữ ngẫu nhiên: ['Saree', 'Linzy', 'Kerianne', 'Sonya', 'Tilly', 'Vernice', 'Gerti', 'Issie', 'Lonni', 'Barbee', 'Carolin', 'Bernadette', 'Saundra', 'Meade', 'Michal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#13. Viết chương trình Python với thư viện NLTK để trích xuất ký tự cuối cùng của tất cả các tên được gắn nhãn và tạo mảng mới với chữ cái cuối cùng của mỗi tên và nhãn được liên kết.\n",
        "last_char_male = [(name[-1], 'male') for name in male_names]\n",
        "last_char_female = [(name[-1], 'female') for name in female_names]\n",
        "\n",
        "last_chars = last_char_male + last_char_female\n",
        "print(\"Ký tự cuối cùng của các tên:\", last_chars[:10])  # In 10 phần tử đầu tiên"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzdc4bUNW9tO",
        "outputId": "1ffdcb48-18fc-4b14-8e40-be9c6cef9d94"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ký tự cuối cùng của các tên: [('r', 'male'), ('n', 'male'), ('y', 'male'), ('e', 'male'), ('t', 'male'), ('t', 'male'), ('y', 'male'), ('l', 'male'), ('l', 'male'), ('m', 'male')]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.3"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}